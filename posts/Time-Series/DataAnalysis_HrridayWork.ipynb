{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Time Series data of UCI-HAR Dataset\n",
    "author: [\"Guntas Singh Saran\", \"Hrriday V. Ruparel\"]\n",
    "date: \"2024-01-24\"\n",
    "format:\n",
    "    html:\n",
    "        code-fold: false\n",
    "        code-tools: true\n",
    "jupyter: python3\n",
    "image: \"output.png\"\n",
    "categories: [\"Classfication\"]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition (Mini Project)\n",
    "## Team: TensionFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from latex import latexify, format_axes\n",
    "import numpy as np\n",
    "import tsfel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "from MakeDataset import *\n",
    "%matplotlib inline\n",
    "# Retina\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Generated from ```MakeDataset.py```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test\n",
    "X_test,X_val,y_test,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.9736077 , -0.1844755 , -0.2821974 ],\n",
       "        [ 0.9760866 , -0.1867793 , -0.2848794 ],\n",
       "        [ 0.977865  , -0.191836  , -0.2891687 ],\n",
       "        ...,\n",
       "        [ 0.9779202 , -0.1834941 , -0.2829651 ],\n",
       "        [ 0.9796224 , -0.1832831 , -0.279844  ],\n",
       "        [ 0.9775468 , -0.1833646 , -0.2764387 ]],\n",
       "\n",
       "       [[ 1.00564   , -0.1732591 , -0.2299191 ],\n",
       "        [ 1.006267  , -0.1727248 , -0.2516695 ],\n",
       "        [ 1.004331  , -0.1783138 , -0.2447012 ],\n",
       "        ...,\n",
       "        [ 0.9963187 , -0.165975  , -0.2166365 ],\n",
       "        [ 0.998345  , -0.1662256 , -0.2176124 ],\n",
       "        [ 1.00105   , -0.1642913 , -0.2210956 ]],\n",
       "\n",
       "       [[ 0.784794  , -0.2597323 , -0.2317497 ],\n",
       "        [ 0.8028195 , -0.2151319 , -0.2276441 ],\n",
       "        [ 0.7250539 , -0.2064177 , -0.2095281 ],\n",
       "        ...,\n",
       "        [ 0.6540971 , -0.140727  , -0.2860766 ],\n",
       "        [ 0.6268603 , -0.2748843 , -0.2455943 ],\n",
       "        [ 0.6052588 , -0.3292142 , -0.1952567 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.013856  , -0.08463204, -0.1833906 ],\n",
       "        [ 1.018295  , -0.08470217, -0.1755404 ],\n",
       "        [ 1.017008  , -0.08552211, -0.1765002 ],\n",
       "        ...,\n",
       "        [ 1.009988  , -0.09727326, -0.1556776 ],\n",
       "        [ 1.009527  , -0.1015205 , -0.1545634 ],\n",
       "        [ 1.012576  , -0.1036466 , -0.1521443 ]],\n",
       "\n",
       "       [[ 1.479893  , -0.4783501 , -0.1348317 ],\n",
       "        [ 1.417838  , -0.5264301 , -0.02401967],\n",
       "        [ 1.12661   , -0.4468493 , -0.05762023],\n",
       "        ...,\n",
       "        [ 0.8351439 , -0.1607123 , -0.1592067 ],\n",
       "        [ 0.7713394 , -0.1248221 , -0.1388356 ],\n",
       "        [ 0.7175624 , -0.1262066 , -0.1470366 ]],\n",
       "\n",
       "       [[ 0.7170605 , -0.02063687, -0.1085871 ],\n",
       "        [ 0.7705297 , -0.0618509 , -0.1241441 ],\n",
       "        [ 0.7802221 , -0.0469533 , -0.1191337 ],\n",
       "        ...,\n",
       "        [ 0.7315363 , -0.1621981 , -0.04988996],\n",
       "        [ 0.7622148 , -0.1765388 , -0.03800902],\n",
       "        [ 0.7644377 , -0.2050919 , -0.02824738]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract $a_x, a_y, a_z$ from ```X_train```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aXYZ_Xtrain = X_train[:, :, 0], X_train[:, :, 1], X_train[:, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Total Acceleration $(a_x^2 + a_y^2 + a_z^2)$ Time Series from ```X_train```, ```X_test```, ```X_val```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_TS = np.sum(np.square(X_train), axis = -1)\n",
    "X_test_TS = np.sum(np.square(X_test), axis = -1)\n",
    "X_val_TS = np.sum(np.square(X_val), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 500) (36, 500) (36, 500)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_TS.shape, X_test_TS.shape, X_val_TS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 2, 3, 6, 4, 1, 5, 5, 4, 3, 1, 6, 5, 4, 1, 5, 1, 4, 6, 2, 4,\n",
       "       6, 3, 6, 1, 1, 6, 6, 2, 5, 1, 4, 2, 6, 4, 3, 3, 6, 4, 2, 3, 6, 3,\n",
       "       5, 5, 3, 1, 3, 1, 4, 6, 4, 5, 4, 4, 3, 4, 2, 4, 2, 1, 2, 5, 4, 2,\n",
       "       5, 2, 3, 6, 1, 3, 2, 2, 1, 3, 6, 2, 5, 1, 3, 2, 4, 5, 4, 2, 1, 1,\n",
       "       1, 3, 5, 5, 6, 1, 4, 6, 6, 5, 3, 3, 2, 6, 6, 3, 1, 5, 2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sort Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 86,  26,  25,  87,  93,  47,  49,  17,  15,  31,  61,  88,  70,\n",
       "        74,  79,   6,  11, 104,  33,  73,  72,  40,  62, 106,  58,  67,\n",
       "        65,  81,  85,  60, 107,  77,   2, 100,  29,  20,  75,   3,  71,\n",
       "       103,  68,  80,  10,  99,  98,  56,  48,  89,  41,  36,  37,  43,\n",
       "        23,  46,  32,  35,   5,  39,   9,  64,  21,  54,  59,  57,  55,\n",
       "        84,  18,  52,  82,  50,  94,  14,  97,  78,  91,  90, 105,  83,\n",
       "         0,  53,  66,  63,   1,  45,  44,   7,  30,   8,  13,  16,   4,\n",
       "       102, 101,  12,  96,  69,  19,  76,  92,  24,  27,  28,  34,  38,\n",
       "        42,  51,  95,  22], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_train_TS)\n",
    "df[\"Label\"] = y_train\n",
    "df.sort_values(by = \"Label\", inplace = True)\n",
    "S = np.array(df.index)\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.714053</td>\n",
       "      <td>0.732246</td>\n",
       "      <td>0.768960</td>\n",
       "      <td>0.853281</td>\n",
       "      <td>0.950569</td>\n",
       "      <td>1.001927</td>\n",
       "      <td>1.025067</td>\n",
       "      <td>1.039051</td>\n",
       "      <td>1.033828</td>\n",
       "      <td>1.021974</td>\n",
       "      <td>...</td>\n",
       "      <td>1.477209</td>\n",
       "      <td>1.245564</td>\n",
       "      <td>0.884933</td>\n",
       "      <td>0.751383</td>\n",
       "      <td>0.895341</td>\n",
       "      <td>1.111554</td>\n",
       "      <td>1.159284</td>\n",
       "      <td>1.061964</td>\n",
       "      <td>0.962311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.751970</td>\n",
       "      <td>0.651734</td>\n",
       "      <td>0.579656</td>\n",
       "      <td>0.587043</td>\n",
       "      <td>0.606218</td>\n",
       "      <td>0.727218</td>\n",
       "      <td>0.797291</td>\n",
       "      <td>0.794672</td>\n",
       "      <td>0.834353</td>\n",
       "      <td>0.888909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396283</td>\n",
       "      <td>0.573048</td>\n",
       "      <td>0.702095</td>\n",
       "      <td>0.827120</td>\n",
       "      <td>0.867516</td>\n",
       "      <td>0.805562</td>\n",
       "      <td>0.813949</td>\n",
       "      <td>0.771488</td>\n",
       "      <td>0.791860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.596975</td>\n",
       "      <td>0.577279</td>\n",
       "      <td>0.564058</td>\n",
       "      <td>0.773096</td>\n",
       "      <td>0.871679</td>\n",
       "      <td>1.057734</td>\n",
       "      <td>1.427447</td>\n",
       "      <td>1.728494</td>\n",
       "      <td>1.920396</td>\n",
       "      <td>1.673412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961942</td>\n",
       "      <td>1.053653</td>\n",
       "      <td>1.100745</td>\n",
       "      <td>1.275938</td>\n",
       "      <td>1.522039</td>\n",
       "      <td>1.531372</td>\n",
       "      <td>1.548665</td>\n",
       "      <td>1.541446</td>\n",
       "      <td>1.412323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.447083</td>\n",
       "      <td>1.243813</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>0.811583</td>\n",
       "      <td>0.683452</td>\n",
       "      <td>0.727751</td>\n",
       "      <td>0.759291</td>\n",
       "      <td>0.818850</td>\n",
       "      <td>0.947241</td>\n",
       "      <td>0.960450</td>\n",
       "      <td>...</td>\n",
       "      <td>1.395899</td>\n",
       "      <td>1.404201</td>\n",
       "      <td>1.532946</td>\n",
       "      <td>2.060462</td>\n",
       "      <td>2.916117</td>\n",
       "      <td>3.367976</td>\n",
       "      <td>2.650901</td>\n",
       "      <td>1.300202</td>\n",
       "      <td>0.516547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.678714</td>\n",
       "      <td>0.700478</td>\n",
       "      <td>1.148305</td>\n",
       "      <td>2.166170</td>\n",
       "      <td>2.921367</td>\n",
       "      <td>2.662965</td>\n",
       "      <td>1.954290</td>\n",
       "      <td>1.440979</td>\n",
       "      <td>1.186594</td>\n",
       "      <td>1.258637</td>\n",
       "      <td>...</td>\n",
       "      <td>1.112212</td>\n",
       "      <td>1.326475</td>\n",
       "      <td>1.516445</td>\n",
       "      <td>1.761912</td>\n",
       "      <td>2.096122</td>\n",
       "      <td>1.985628</td>\n",
       "      <td>1.334452</td>\n",
       "      <td>0.939196</td>\n",
       "      <td>0.868019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.996194</td>\n",
       "      <td>0.991963</td>\n",
       "      <td>0.984747</td>\n",
       "      <td>0.987995</td>\n",
       "      <td>0.992127</td>\n",
       "      <td>0.994089</td>\n",
       "      <td>0.995440</td>\n",
       "      <td>0.998901</td>\n",
       "      <td>1.003637</td>\n",
       "      <td>1.002344</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010409</td>\n",
       "      <td>1.008286</td>\n",
       "      <td>1.004564</td>\n",
       "      <td>1.001250</td>\n",
       "      <td>0.997999</td>\n",
       "      <td>0.996779</td>\n",
       "      <td>0.991216</td>\n",
       "      <td>0.983254</td>\n",
       "      <td>0.985567</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.030783</td>\n",
       "      <td>1.005243</td>\n",
       "      <td>0.994559</td>\n",
       "      <td>0.997765</td>\n",
       "      <td>1.005931</td>\n",
       "      <td>1.004629</td>\n",
       "      <td>0.970352</td>\n",
       "      <td>0.929467</td>\n",
       "      <td>0.959656</td>\n",
       "      <td>1.012440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978252</td>\n",
       "      <td>1.000408</td>\n",
       "      <td>1.027792</td>\n",
       "      <td>1.028454</td>\n",
       "      <td>1.006944</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.983824</td>\n",
       "      <td>0.990666</td>\n",
       "      <td>0.990392</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.017841</td>\n",
       "      <td>1.016995</td>\n",
       "      <td>1.024412</td>\n",
       "      <td>1.029757</td>\n",
       "      <td>1.026955</td>\n",
       "      <td>1.028478</td>\n",
       "      <td>1.026419</td>\n",
       "      <td>1.026562</td>\n",
       "      <td>1.034466</td>\n",
       "      <td>1.037380</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035634</td>\n",
       "      <td>1.040731</td>\n",
       "      <td>1.038952</td>\n",
       "      <td>1.027263</td>\n",
       "      <td>1.011913</td>\n",
       "      <td>1.013323</td>\n",
       "      <td>1.020733</td>\n",
       "      <td>1.019209</td>\n",
       "      <td>1.022797</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.003037</td>\n",
       "      <td>1.000143</td>\n",
       "      <td>1.002048</td>\n",
       "      <td>0.993890</td>\n",
       "      <td>0.997013</td>\n",
       "      <td>1.012518</td>\n",
       "      <td>1.025586</td>\n",
       "      <td>1.026735</td>\n",
       "      <td>1.021032</td>\n",
       "      <td>1.016388</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010742</td>\n",
       "      <td>1.016365</td>\n",
       "      <td>1.022836</td>\n",
       "      <td>1.018828</td>\n",
       "      <td>1.014693</td>\n",
       "      <td>1.025160</td>\n",
       "      <td>1.033535</td>\n",
       "      <td>1.029625</td>\n",
       "      <td>1.023284</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.027639</td>\n",
       "      <td>1.033972</td>\n",
       "      <td>1.033586</td>\n",
       "      <td>1.024781</td>\n",
       "      <td>1.022987</td>\n",
       "      <td>1.022073</td>\n",
       "      <td>1.025497</td>\n",
       "      <td>1.025356</td>\n",
       "      <td>1.019591</td>\n",
       "      <td>1.021240</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031073</td>\n",
       "      <td>1.032912</td>\n",
       "      <td>1.032843</td>\n",
       "      <td>1.028517</td>\n",
       "      <td>1.027242</td>\n",
       "      <td>1.030718</td>\n",
       "      <td>1.032342</td>\n",
       "      <td>1.033870</td>\n",
       "      <td>1.031274</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "86  0.714053  0.732246  0.768960  0.853281  0.950569  1.001927  1.025067   \n",
       "26  0.751970  0.651734  0.579656  0.587043  0.606218  0.727218  0.797291   \n",
       "25  0.596975  0.577279  0.564058  0.773096  0.871679  1.057734  1.427447   \n",
       "87  1.447083  1.243813  0.999385  0.811583  0.683452  0.727751  0.759291   \n",
       "93  0.678714  0.700478  1.148305  2.166170  2.921367  2.662965  1.954290   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "38  0.996194  0.991963  0.984747  0.987995  0.992127  0.994089  0.995440   \n",
       "42  1.030783  1.005243  0.994559  0.997765  1.005931  1.004629  0.970352   \n",
       "51  1.017841  1.016995  1.024412  1.029757  1.026955  1.028478  1.026419   \n",
       "95  1.003037  1.000143  1.002048  0.993890  0.997013  1.012518  1.025586   \n",
       "22  1.027639  1.033972  1.033586  1.024781  1.022987  1.022073  1.025497   \n",
       "\n",
       "           7         8         9  ...       491       492       493       494  \\\n",
       "86  1.039051  1.033828  1.021974  ...  1.477209  1.245564  0.884933  0.751383   \n",
       "26  0.794672  0.834353  0.888909  ...  0.396283  0.573048  0.702095  0.827120   \n",
       "25  1.728494  1.920396  1.673412  ...  0.961942  1.053653  1.100745  1.275938   \n",
       "87  0.818850  0.947241  0.960450  ...  1.395899  1.404201  1.532946  2.060462   \n",
       "93  1.440979  1.186594  1.258637  ...  1.112212  1.326475  1.516445  1.761912   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "38  0.998901  1.003637  1.002344  ...  1.010409  1.008286  1.004564  1.001250   \n",
       "42  0.929467  0.959656  1.012440  ...  0.978252  1.000408  1.027792  1.028454   \n",
       "51  1.026562  1.034466  1.037380  ...  1.035634  1.040731  1.038952  1.027263   \n",
       "95  1.026735  1.021032  1.016388  ...  1.010742  1.016365  1.022836  1.018828   \n",
       "22  1.025356  1.019591  1.021240  ...  1.031073  1.032912  1.032843  1.028517   \n",
       "\n",
       "         495       496       497       498       499  Label  \n",
       "86  0.895341  1.111554  1.159284  1.061964  0.962311      1  \n",
       "26  0.867516  0.805562  0.813949  0.771488  0.791860      1  \n",
       "25  1.522039  1.531372  1.548665  1.541446  1.412323      1  \n",
       "87  2.916117  3.367976  2.650901  1.300202  0.516547      1  \n",
       "93  2.096122  1.985628  1.334452  0.939196  0.868019      1  \n",
       "..       ...       ...       ...       ...       ...    ...  \n",
       "38  0.997999  0.996779  0.991216  0.983254  0.985567      6  \n",
       "42  1.006944  0.987428  0.983824  0.990666  0.990392      6  \n",
       "51  1.011913  1.013323  1.020733  1.019209  1.022797      6  \n",
       "95  1.014693  1.025160  1.033535  1.029625  1.023284      6  \n",
       "22  1.027242  1.030718  1.032342  1.033870  1.031274      6  \n",
       "\n",
       "[108 rows x 501 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the $a_x, a_y, a_z$ also as according to the Label sort index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aXYZ_Xtrain = aXYZ_Xtrain[0][S], aXYZ_Xtrain[1][S], aXYZ_Xtrain[2][S]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the total acceleration $(a_x^2 + a_y^2 + a_z^2)$ according to label sort index and get the FINAL TIME SERIES for all test data subjects $108$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.714053</td>\n",
       "      <td>0.732246</td>\n",
       "      <td>0.768960</td>\n",
       "      <td>0.853281</td>\n",
       "      <td>0.950569</td>\n",
       "      <td>1.001927</td>\n",
       "      <td>1.025067</td>\n",
       "      <td>1.039051</td>\n",
       "      <td>1.033828</td>\n",
       "      <td>1.021974</td>\n",
       "      <td>...</td>\n",
       "      <td>1.477209</td>\n",
       "      <td>1.245564</td>\n",
       "      <td>0.884933</td>\n",
       "      <td>0.751383</td>\n",
       "      <td>0.895341</td>\n",
       "      <td>1.111554</td>\n",
       "      <td>1.159284</td>\n",
       "      <td>1.061964</td>\n",
       "      <td>0.962311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.751970</td>\n",
       "      <td>0.651734</td>\n",
       "      <td>0.579656</td>\n",
       "      <td>0.587043</td>\n",
       "      <td>0.606218</td>\n",
       "      <td>0.727218</td>\n",
       "      <td>0.797291</td>\n",
       "      <td>0.794672</td>\n",
       "      <td>0.834353</td>\n",
       "      <td>0.888909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396283</td>\n",
       "      <td>0.573048</td>\n",
       "      <td>0.702095</td>\n",
       "      <td>0.827120</td>\n",
       "      <td>0.867516</td>\n",
       "      <td>0.805562</td>\n",
       "      <td>0.813949</td>\n",
       "      <td>0.771488</td>\n",
       "      <td>0.791860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.596975</td>\n",
       "      <td>0.577279</td>\n",
       "      <td>0.564058</td>\n",
       "      <td>0.773096</td>\n",
       "      <td>0.871679</td>\n",
       "      <td>1.057734</td>\n",
       "      <td>1.427447</td>\n",
       "      <td>1.728494</td>\n",
       "      <td>1.920396</td>\n",
       "      <td>1.673412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961942</td>\n",
       "      <td>1.053653</td>\n",
       "      <td>1.100745</td>\n",
       "      <td>1.275938</td>\n",
       "      <td>1.522039</td>\n",
       "      <td>1.531372</td>\n",
       "      <td>1.548665</td>\n",
       "      <td>1.541446</td>\n",
       "      <td>1.412323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.447083</td>\n",
       "      <td>1.243813</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>0.811583</td>\n",
       "      <td>0.683452</td>\n",
       "      <td>0.727751</td>\n",
       "      <td>0.759291</td>\n",
       "      <td>0.818850</td>\n",
       "      <td>0.947241</td>\n",
       "      <td>0.960450</td>\n",
       "      <td>...</td>\n",
       "      <td>1.395899</td>\n",
       "      <td>1.404201</td>\n",
       "      <td>1.532946</td>\n",
       "      <td>2.060462</td>\n",
       "      <td>2.916117</td>\n",
       "      <td>3.367976</td>\n",
       "      <td>2.650901</td>\n",
       "      <td>1.300202</td>\n",
       "      <td>0.516547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.678714</td>\n",
       "      <td>0.700478</td>\n",
       "      <td>1.148305</td>\n",
       "      <td>2.166170</td>\n",
       "      <td>2.921367</td>\n",
       "      <td>2.662965</td>\n",
       "      <td>1.954290</td>\n",
       "      <td>1.440979</td>\n",
       "      <td>1.186594</td>\n",
       "      <td>1.258637</td>\n",
       "      <td>...</td>\n",
       "      <td>1.112212</td>\n",
       "      <td>1.326475</td>\n",
       "      <td>1.516445</td>\n",
       "      <td>1.761912</td>\n",
       "      <td>2.096122</td>\n",
       "      <td>1.985628</td>\n",
       "      <td>1.334452</td>\n",
       "      <td>0.939196</td>\n",
       "      <td>0.868019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.996194</td>\n",
       "      <td>0.991963</td>\n",
       "      <td>0.984747</td>\n",
       "      <td>0.987995</td>\n",
       "      <td>0.992127</td>\n",
       "      <td>0.994089</td>\n",
       "      <td>0.995440</td>\n",
       "      <td>0.998901</td>\n",
       "      <td>1.003637</td>\n",
       "      <td>1.002344</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010409</td>\n",
       "      <td>1.008286</td>\n",
       "      <td>1.004564</td>\n",
       "      <td>1.001250</td>\n",
       "      <td>0.997999</td>\n",
       "      <td>0.996779</td>\n",
       "      <td>0.991216</td>\n",
       "      <td>0.983254</td>\n",
       "      <td>0.985567</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.030783</td>\n",
       "      <td>1.005243</td>\n",
       "      <td>0.994559</td>\n",
       "      <td>0.997765</td>\n",
       "      <td>1.005931</td>\n",
       "      <td>1.004629</td>\n",
       "      <td>0.970352</td>\n",
       "      <td>0.929467</td>\n",
       "      <td>0.959656</td>\n",
       "      <td>1.012440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978252</td>\n",
       "      <td>1.000408</td>\n",
       "      <td>1.027792</td>\n",
       "      <td>1.028454</td>\n",
       "      <td>1.006944</td>\n",
       "      <td>0.987428</td>\n",
       "      <td>0.983824</td>\n",
       "      <td>0.990666</td>\n",
       "      <td>0.990392</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1.017841</td>\n",
       "      <td>1.016995</td>\n",
       "      <td>1.024412</td>\n",
       "      <td>1.029757</td>\n",
       "      <td>1.026955</td>\n",
       "      <td>1.028478</td>\n",
       "      <td>1.026419</td>\n",
       "      <td>1.026562</td>\n",
       "      <td>1.034466</td>\n",
       "      <td>1.037380</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035634</td>\n",
       "      <td>1.040731</td>\n",
       "      <td>1.038952</td>\n",
       "      <td>1.027263</td>\n",
       "      <td>1.011913</td>\n",
       "      <td>1.013323</td>\n",
       "      <td>1.020733</td>\n",
       "      <td>1.019209</td>\n",
       "      <td>1.022797</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.003037</td>\n",
       "      <td>1.000143</td>\n",
       "      <td>1.002048</td>\n",
       "      <td>0.993890</td>\n",
       "      <td>0.997013</td>\n",
       "      <td>1.012518</td>\n",
       "      <td>1.025586</td>\n",
       "      <td>1.026735</td>\n",
       "      <td>1.021032</td>\n",
       "      <td>1.016388</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010742</td>\n",
       "      <td>1.016365</td>\n",
       "      <td>1.022836</td>\n",
       "      <td>1.018828</td>\n",
       "      <td>1.014693</td>\n",
       "      <td>1.025160</td>\n",
       "      <td>1.033535</td>\n",
       "      <td>1.029625</td>\n",
       "      <td>1.023284</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.027639</td>\n",
       "      <td>1.033972</td>\n",
       "      <td>1.033586</td>\n",
       "      <td>1.024781</td>\n",
       "      <td>1.022987</td>\n",
       "      <td>1.022073</td>\n",
       "      <td>1.025497</td>\n",
       "      <td>1.025356</td>\n",
       "      <td>1.019591</td>\n",
       "      <td>1.021240</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031073</td>\n",
       "      <td>1.032912</td>\n",
       "      <td>1.032843</td>\n",
       "      <td>1.028517</td>\n",
       "      <td>1.027242</td>\n",
       "      <td>1.030718</td>\n",
       "      <td>1.032342</td>\n",
       "      <td>1.033870</td>\n",
       "      <td>1.031274</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.714053  0.732246  0.768960  0.853281  0.950569  1.001927  1.025067   \n",
       "1    0.751970  0.651734  0.579656  0.587043  0.606218  0.727218  0.797291   \n",
       "2    0.596975  0.577279  0.564058  0.773096  0.871679  1.057734  1.427447   \n",
       "3    1.447083  1.243813  0.999385  0.811583  0.683452  0.727751  0.759291   \n",
       "4    0.678714  0.700478  1.148305  2.166170  2.921367  2.662965  1.954290   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "103  0.996194  0.991963  0.984747  0.987995  0.992127  0.994089  0.995440   \n",
       "104  1.030783  1.005243  0.994559  0.997765  1.005931  1.004629  0.970352   \n",
       "105  1.017841  1.016995  1.024412  1.029757  1.026955  1.028478  1.026419   \n",
       "106  1.003037  1.000143  1.002048  0.993890  0.997013  1.012518  1.025586   \n",
       "107  1.027639  1.033972  1.033586  1.024781  1.022987  1.022073  1.025497   \n",
       "\n",
       "            7         8         9  ...       491       492       493  \\\n",
       "0    1.039051  1.033828  1.021974  ...  1.477209  1.245564  0.884933   \n",
       "1    0.794672  0.834353  0.888909  ...  0.396283  0.573048  0.702095   \n",
       "2    1.728494  1.920396  1.673412  ...  0.961942  1.053653  1.100745   \n",
       "3    0.818850  0.947241  0.960450  ...  1.395899  1.404201  1.532946   \n",
       "4    1.440979  1.186594  1.258637  ...  1.112212  1.326475  1.516445   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "103  0.998901  1.003637  1.002344  ...  1.010409  1.008286  1.004564   \n",
       "104  0.929467  0.959656  1.012440  ...  0.978252  1.000408  1.027792   \n",
       "105  1.026562  1.034466  1.037380  ...  1.035634  1.040731  1.038952   \n",
       "106  1.026735  1.021032  1.016388  ...  1.010742  1.016365  1.022836   \n",
       "107  1.025356  1.019591  1.021240  ...  1.031073  1.032912  1.032843   \n",
       "\n",
       "          494       495       496       497       498       499  Label  \n",
       "0    0.751383  0.895341  1.111554  1.159284  1.061964  0.962311      1  \n",
       "1    0.827120  0.867516  0.805562  0.813949  0.771488  0.791860      1  \n",
       "2    1.275938  1.522039  1.531372  1.548665  1.541446  1.412323      1  \n",
       "3    2.060462  2.916117  3.367976  2.650901  1.300202  0.516547      1  \n",
       "4    1.761912  2.096122  1.985628  1.334452  0.939196  0.868019      1  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "103  1.001250  0.997999  0.996779  0.991216  0.983254  0.985567      6  \n",
       "104  1.028454  1.006944  0.987428  0.983824  0.990666  0.990392      6  \n",
       "105  1.027263  1.011913  1.013323  1.020733  1.019209  1.022797      6  \n",
       "106  1.018828  1.014693  1.025160  1.033535  1.029625  1.023284      6  \n",
       "107  1.028517  1.027242  1.030718  1.032342  1.033870  1.031274      6  \n",
       "\n",
       "[108 rows x 501 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Xtrain = pd.DataFrame(X_train_TS)\n",
    "df_Xtrain[\"Label\"] = y_train\n",
    "df_Xtrain.sort_values(by = \"Label\", inplace = True)\n",
    "df_Xtrain.set_index(pd.Series(range(108)), inplace = True)\n",
    "df_Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    18\n",
       "2    18\n",
       "3    18\n",
       "4    18\n",
       "5    18\n",
       "6    18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Xtrain[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WALKING': 1,\n",
       " 'WALKING_UPSTAIRS': 2,\n",
       " 'WALKING_DOWNSTAIRS': 3,\n",
       " 'SITTING': 4,\n",
       " 'STANDING': 5,\n",
       " 'LAYING': 6}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'WALKING',\n",
       " 2: 'WALKING_UPSTAIRS',\n",
       " 3: 'WALKING_DOWNSTAIRS',\n",
       " 4: 'SITTING',\n",
       " 5: 'STANDING',\n",
       " 6: 'LAYING'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classesN = {1 : 'WALKING', 2 : 'WALKING_UPSTAIRS', 3 : 'WALKING_DOWNSTAIRS', 4 : 'SITTING', 5 : 'STANDING', 6 : 'LAYING'}\n",
    "classesN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions/Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Plot the waveform for data from each activity class. Are you able to see any difference/similarities between the activities? You can plot a subplot having 6 colunms to show differences/similarities between the activities. Do you think the model will be able to classify the activities based on the data? **[1 mark]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of each $(a_x, a_y, a_z)$ for all subjects<br>\n",
    "$ (a_x, a_y, a_z) = [\\text{Red}, \\text{Green}, \\text{Blue}] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(18, 6, figsize = (25, 27.5))\n",
    "fig.suptitle(r\"Time Series of Acceleration $(acc_x, acc_y, acc_z)$\", size = 24)\n",
    "sortedY_train = np.array(df_Xtrain[\"Label\"])\n",
    "colors = [\"red\", \"green\", \"blue\"]\n",
    "c = 0\n",
    "for i in range(6):\n",
    "    for j in range(18):\n",
    "        for k in range(3):\n",
    "            time_series = aXYZ_Xtrain[k][c]\n",
    "            axes[j, i].plot(time_series, color = colors[k], linewidth = 3)\n",
    "            axes[j, i].set_title(f\"Subject {c + 1}, Class = {classesN[sortedY_train[c]]}\", fontsize = 9)\n",
    "            axes[j, i].set_ylabel(r\"Acceleration in $ms^{-2}/g$\", fontsize = 6)\n",
    "            axes[j, i].set_xlabel(\"Time Samples\", fontsize = 6)\n",
    "        c += 1\n",
    "\n",
    "\n",
    "# plt.subplots_adjust(wspace = 0.5, hspace = 0.5)\n",
    "# plt.savefig(\"Activity_Individual.png\")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:<br>\n",
    "#### 1. From the above plots, one can easily differentiate between Static Activities (like Laying, Sitting, Standing) and Dynamic Activities (Walking, Walking Downstairs, Walking Upstairs) as the Dynamic Activities are more volatile and seem to have greater variance as compared to the Static Activities.\n",
    "\n",
    "#### 2. Among subjects belonging to the same class, there is a certain degree of similarity in the trends of time series data. \n",
    "\n",
    "#### 3. The model may be capable of classifying the activites into Static and Dynamic, though further classification may depend on many factors like model hyperparameters, feature matrix, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Do you think we need a machine learning model to differentiate between static activities (laying, sitting, standing) and dynamic activities(walking, walking_downstairs, walking_upstairs)? Look at the linear acceleration $(acc_x^2 + acc_y^2 + acc_z^2)$ for each activity and justify your answer. **[1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "latexify()\n",
    "fig, axes = plt.subplots(18, 6, figsize = (25, 27.5))\n",
    "fig.suptitle(r\"Time Series of Total Acceleration $(acc_x^2 + acc_y^2 + acc_z^2)$\", size = 24)\n",
    "sortedY_train = np.array(df_Xtrain[\"Label\"])\n",
    "colors = [\"red\", \"deeppink\", \"purple\", \"teal\", \"green\", \"blue\"]\n",
    "c = 0\n",
    "for i in range(6):\n",
    "    for j in range(18):\n",
    "        time_series = df_Xtrain.iloc[c, : -1]\n",
    "        axes[j, i].plot(time_series, color = colors[i], linewidth = 4)\n",
    "        axes[j, i].set_title(f\"Subject {c + 1}, Class = {classesN[sortedY_train[c]]}\", fontsize = 9)\n",
    "        axes[j, i].set_ylabel(r\"Total Acceleration in  $m^{2}s^{-4}/g^2$\", fontsize = 6)\n",
    "        axes[j, i].set_xlabel(\"Time Samples\", fontsize = 6)\n",
    "        c += 1\n",
    "\n",
    "# plt.subplots_adjust(wspace = 0.5, hspace = 0.5)\n",
    "# plt.savefig(\"Activity_Tot.png\")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: \n",
    "#### 1. For differentiating between Static and Dynamic Activities, implementation of a machine learning model may not be necessary but it may be a sufficient condition.\n",
    "\n",
    "#### 2. One can always extract time series features from the samples of activities and draw meaningful inferences out of it. \n",
    "\n",
    "#### 3. A more automated way of the same would be to implement a machine learning model that learns the distribution of data.\n",
    "\n",
    "#### 4. A simple machine learning model like a Decision Tree Classifier might work well in classifying between Static and Dynamic activites as the Dynamic Activities are more volatile and seem to have greater variance as compared to the Static Activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train Decision Tree using trainset and report Accuracy and confusion matrix using testset. **[1 mark]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw Time Series for $108$ Training Subjects and $500$ features/samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 6, 1, 6, 5, 6, 1, 1, 1, 4, 6, 6, 5, 2, 6, 5, 5, 3, 6, 4, 1,\n",
       "       4, 5, 2, 1, 3, 6, 1, 4, 6, 6, 6, 1, 1, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)\n",
    "clfg = model.fit(X_train_TS, y_train)\n",
    "y_pred = clfg.predict(X_test_TS)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Accuracy} = \\frac{||y = \\hat{y}||}{||y||}$<br>\n",
    "\n",
    "$\\text{Precision} = \\frac{||y = \\hat{y} = \\text{Class}||}{||\\hat{y} = \\text{Class}||} = \\frac{\\text{T.P.}}{\\text{T.P.} + \\text{F.P.}}$<br>\n",
    "\n",
    "$\\text{Recall} = \\frac{||y = \\hat{y} = \\text{Class}||}{||y = \\text{Class}||} = \\frac{\\text{T.P.}}{\\text{T.P.} + \\text{F.N.}}$<br>\n",
    "\n",
    "$\\text{F-Score} = \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.67      0.50         6\n",
      "           2       0.50      0.17      0.25         6\n",
      "           3       0.33      0.17      0.22         6\n",
      "           4       0.50      0.33      0.40         6\n",
      "           5       1.00      0.83      0.91         6\n",
      "           6       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.53        36\n",
      "   macro avg       0.54      0.53      0.49        36\n",
      "weighted avg       0.54      0.53      0.49        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index = [classT for classT in classes], columns = [classT for classT in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix Plot Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## flag = 1 for a single plot and 0 for subplots for 2 - 8 depths\n",
    "def confMatrix(dataFrame, flag = 1, accuracies = None):\n",
    "    if flag:\n",
    "        plt.figure(figsize = (15, 15))\n",
    "        ax = sns.heatmap(dataFrame, annot = True, cmap = \"PuBu\")\n",
    "        plt.setp(ax.get_xticklabels(), rotation = 45, fontsize = 8)\n",
    "        plt.setp(ax.get_yticklabels(), fontsize = 8)\n",
    "        plt.ylabel(\"True label\", fontsize = 18)\n",
    "        plt.xlabel(\"Predicted label\", fontsize = 18)\n",
    "        plt.title(f\"Accuracy = {accuracy_score(y_test, y_pred)*100: .4f}%\", fontweight = \"bold\", fontsize = 13)\n",
    "        plt.savefig(\"Single_ConfusionM.png\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig, axes = plt.subplots(3, 3, figsize = (25, 25))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, df in enumerate(dataFrame):\n",
    "            ax = sns.heatmap(df, annot = True, ax = axes[i], cbar = False, cmap = \"PuBu\")\n",
    "            \n",
    "            plt.setp(ax.get_xticklabels(), rotation = 45, fontsize = 6)\n",
    "            plt.setp(ax.get_yticklabels(), fontsize = 8)\n",
    "            ax.set_title(f\"Depth = {i + 2}\\nAccuracy = {accuracies[i] * 100: .4f}%\", fontsize = 10)\n",
    "            ax.set_ylabel(\"True label\", fontsize = 12)\n",
    "            ax.set_xlabel(\"Predicted label\", fontsize = 12)\n",
    "            \n",
    "        plt.delaxes(axes[7])\n",
    "        plt.delaxes(axes[8])\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(wspace = 1.1, hspace = 1.1)\n",
    "        plt.savefig(\"DepthConfusionM.png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confMatrix(df_cm, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:<br>\n",
    "#### 1. The overall performance of the Decision Tree Classifier model trained on the raw total acceleration $(acc_x^2 + acc_y^2 + acc_z^2)$ dataset was on average barely better than a fair coin toss.\n",
    "\n",
    "#### 2. The model performed decently well in classifying between Static and Dynamic Activities. \n",
    "\n",
    "#### 3. Classification among the Static Activities: \n",
    "* The model performed the best in classifying the activity STANDING, while it mispredicted LAYING as SITTING. \n",
    "* On the contrary, classifications among the Dynamic Activities showed confusion.\n",
    "\n",
    "#### 4. NOTE: The above observations are specific to a single random model and cannot be generalized for any model. Additionally, the number of samples available for training and testing are quite few hence, nothing much can be said about the distributions of activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Decision Tree with varying depths (2-8) using trainset and report accuracy and confusion matrix using Test set. Does the accuracy change when the depth is increased? Plot the accuracies and reason why such a result has been obtained. **[1 mark]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varying Tree Depths $(2 - 8)$ and looking at the results for each depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices, class_reports, class_reports_dict, accuracies = [], [], [], []\n",
    "for i in range(2, 9):\n",
    "    model = DecisionTreeClassifier(max_depth = i,random_state=42)\n",
    "    clfg = model.fit(X_train_TS, y_train)\n",
    "    y_pred = clfg.predict(X_test_TS)\n",
    "    \n",
    "    pred, actual = y_pred, y_test\n",
    "    \n",
    "    cm = confusion_matrix(actual, pred)\n",
    "    \n",
    "    confusion_matrices.append(pd.DataFrame(cm, index = [classT for classT in classes], columns = [classT for classT in classes]))\n",
    "    class_reports.append(classification_report(actual, pred, labels = np.unique(pred)))\n",
    "    class_reports_dict.append(classification_report(actual, pred, labels = np.unique(pred), output_dict = True))\n",
    "    accuracies.append(accuracy_score(actual, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix Image (for varying tree depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confMatrix(confusion_matrices, 0, accuracies = accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth = 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.50      0.43         6\n",
      "           3       0.50      0.17      0.25         6\n",
      "           5       0.75      1.00      0.86         6\n",
      "           6       0.33      1.00      0.50         6\n",
      "\n",
      "   micro avg       0.44      0.67      0.53        24\n",
      "   macro avg       0.49      0.67      0.51        24\n",
      "weighted avg       0.49      0.67      0.51        24\n",
      "\n",
      "\n",
      "\n",
      "Depth = 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.50      0.50         6\n",
      "           2       1.00      0.17      0.29         6\n",
      "           3       0.50      0.33      0.40         6\n",
      "           4       0.29      0.33      0.31         6\n",
      "           5       0.86      1.00      0.92         6\n",
      "           6       0.55      1.00      0.71         6\n",
      "\n",
      "    accuracy                           0.56        36\n",
      "   macro avg       0.61      0.56      0.52        36\n",
      "weighted avg       0.61      0.56      0.52        36\n",
      "\n",
      "\n",
      "\n",
      "Depth = 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.67      0.57         6\n",
      "           2       0.50      0.17      0.25         6\n",
      "           3       0.33      0.17      0.22         6\n",
      "           4       0.29      0.33      0.31         6\n",
      "           5       1.00      0.83      0.91         6\n",
      "           6       0.55      1.00      0.71         6\n",
      "\n",
      "    accuracy                           0.53        36\n",
      "   macro avg       0.53      0.53      0.49        36\n",
      "weighted avg       0.53      0.53      0.49        36\n",
      "\n",
      "\n",
      "\n",
      "Depth = 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.83      0.59         6\n",
      "           2       0.50      0.17      0.25         6\n",
      "           3       0.50      0.17      0.25         6\n",
      "           4       0.40      0.33      0.36         6\n",
      "           5       1.00      0.83      0.91         6\n",
      "           6       0.55      1.00      0.71         6\n",
      "\n",
      "    accuracy                           0.56        36\n",
      "   macro avg       0.57      0.56      0.51        36\n",
      "weighted avg       0.57      0.56      0.51        36\n",
      "\n",
      "\n",
      "\n",
      "Depth = 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.83      0.67         6\n",
      "           2       0.33      0.17      0.22         6\n",
      "           3       0.50      0.17      0.25         6\n",
      "           4       0.50      0.33      0.40         6\n",
      "           5       0.83      0.83      0.83         6\n",
      "           6       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.56        36\n",
      "   macro avg       0.54      0.56      0.51        36\n",
      "weighted avg       0.54      0.56      0.51        36\n",
      "\n",
      "\n",
      "\n",
      "Depth = 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.67      0.50         6\n",
      "           2       0.50      0.17      0.25         6\n",
      "           3       0.33      0.17      0.22         6\n",
      "           4       0.50      0.33      0.40         6\n",
      "           5       1.00      0.83      0.91         6\n",
      "           6       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.53        36\n",
      "   macro avg       0.54      0.53      0.49        36\n",
      "weighted avg       0.54      0.53      0.49        36\n",
      "\n",
      "\n",
      "\n",
      "Depth = 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.67      0.50         6\n",
      "           2       0.50      0.17      0.25         6\n",
      "           3       0.33      0.17      0.22         6\n",
      "           4       0.50      0.33      0.40         6\n",
      "           5       1.00      0.83      0.91         6\n",
      "           6       0.50      1.00      0.67         6\n",
      "\n",
      "    accuracy                           0.53        36\n",
      "   macro avg       0.54      0.53      0.49        36\n",
      "weighted avg       0.54      0.53      0.49        36\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,9):\n",
    "    print(f'Depth = {i}\\n{class_reports[i-2]}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "#### 1. From the classification reports, one can infer that the accuracy of classifying activities is in general increasing.\n",
    "\n",
    "#### 2. At $\\text{Depth} = 2$, the model seems to underfit the data which is evident from its large number of misclassifications of Dynamic Activities as Static ones and classification of only a few number of activities (model did not make a single prediction for acivities WALKING UPSTAIRS and SITTING).  \n",
    "\n",
    "#### 3. The accuracy peaks at $\\text{Depth} = 5$ and  $\\text{Depth} = 6$ equivalent to an expected peak in accuracy at higher depths. \n",
    "\n",
    "#### 4. _NOTE: The above observations are specific to a selected random model and cannot be generalized for any model. Additionally, the number of samples available for training and testing are quite few hence, nothing much can be said about the distributions of activities._   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use PCA (Principal Component Analysis) on Total Acceleration $(acc_x^2 + acc_y^2 + acc_z^2)$ to compress the acceleration timeseries into two features and plot a scatter plot to visualize different class of activities. Next, use TSFEL (a featurizer library) to create features (your choice which ones you feel are useful) and then perform PCA to obtain two features. Plot a scatter plot to visualize different class of activities. Are you able to see any difference? **[2 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFER TO ```FeaturesExtr.ipynb``` for further"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
